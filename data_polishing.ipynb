{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae0f13a-4225-402f-be9b-675716c62fcd",
   "metadata": {},
   "source": [
    "Keys added:\n",
    "\n",
    "* 'CID (canonical)': unique indetifier. Submission w/ same structure had same CID. Duplicates were removed â€”description combined.\n",
    "* 'old_index': the order in which they were added in the postera site is kind of sequential\n",
    "* 'clean_creator': the cleaned up creator field\n",
    "* 'SMILES': this may be pre-reaction covalent\n",
    "* 'new_smiles': smiles found in crystal\n",
    "* 'fragments': inspirations. DIRTY AS OF 15/12/22. Not combined w/ cleaned set\n",
    "* 'xcode': according to Fragalysis\n",
    "* 'Structure ID': according to Postera\n",
    "* 'site_name': fragalysis site\n",
    "* 'pdb_entry'\n",
    "* 'submission_date': from IC50 file\n",
    "* 'inferred_submission_date': isotonic regression of the above\n",
    "* 'order_date': true\n",
    "* 'shipment_date': true \n",
    "* 'description': rationale + submission notes\n",
    "* 'N_creator_submission': compounds in submission group N_creator_submission\n",
    "* 'N_submission_group':\n",
    "* 'resubmitted': was this submitted multiple times\n",
    "* 'Enamine - REAL Space', 'Enamine - Extended REAL Space', 'Enamine - SCR', 'Enamine - BB', 'Mcule', 'Mcule Ultimate',\n",
    "* 'N_chars', 'N_words', 'N_words_cutoff'\n",
    "* keyword classification: 'classified_method'\n",
    "* 'flesch', 'dale_chall': readability indices (>20 words or more)\n",
    "* 'okay': keep?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c7595-fe2d-4593-a406-2b49d35b5757",
   "metadata": {},
   "source": [
    "## Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72378865-887a-4e8e-885e-9e05cece902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q PyGithub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a151cb2a-40c3-4373-85c0-e24e7d6bb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from typing import IO\n",
    "from github import Github\n",
    "\n",
    "user = 'postera-ai'\n",
    "repo_name = 'COVID_moonshot_submissions'\n",
    "filename = 'downloaded_COVID_submissions_file.csv'\n",
    "\n",
    "repo = Github().get_user(user).get_repo(repo_name)\n",
    "spreadsheet_url = repo.get_contents(filename).download_url\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "response: requests.Response = requests.get(spreadsheet_url)\n",
    "response.raise_for_status()\n",
    "csv_handle: IO = StringIO(response.text)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "moonshot = pd.read_csv(csv_handle, low_memory=False)\n",
    "# the table contains multiple rows/submitted compounds per submission.\n",
    "# Say the CID `ANT-DIA-3c79be55-1` finishes in `-1`\n",
    "moonshot['CID_group']=moonshot['CID (canonical)'].fillna('').str.extract(r'(.*)\\-\\d+')\n",
    "\n",
    "# force-standarise the dataframe!\n",
    "_choices = {row.name: set(map(type, row.unique())) for i, row in moonshot.transpose().iterrows()}\n",
    "moonshot = moonshot.assign(\n",
    "    **{k: moonshot[k].fillna(False).astype(bool) for k, v in _choices.items() if bool in v},\n",
    "    **{k: moonshot[k].fillna('').astype(str) for k, v in _choices.items() if str in v})\n",
    "\n",
    "# defrag\n",
    "moonshot = moonshot.copy()\n",
    "\n",
    "# fix dates\n",
    "for k in ('ORDER_DATE','SHIPMENT_DATE'):\n",
    "    moonshot[k.lower()] = pd.to_datetime(moonshot[k], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "moonshot['order_month'] = moonshot['order_date'].apply(lambda d: d.month + 12 * (d.year -2020))\n",
    "moonshot['shipment_month'] = moonshot['shipment_date'].apply(lambda d: d.month + 12 * (d.year -2020))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4469d55-8ec4-4da5-9659-8fec0ac6058f",
   "metadata": {},
   "source": [
    "## Combine rationale and Submission notes\n",
    "Reason: nobody understood the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9662f94d-b424-4f90-8453-bb7b7c82569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moonshot['description'] = (moonshot['rationale'].fillna('') +'. ' + moonshot['Submission Notes'].fillna('') +'. ')\\\n",
    "                    .astype(str)\\\n",
    "                    .str.strip()\\\n",
    "                    .str.replace('..', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a9b74-48f5-422b-921b-ad1afd693a32",
   "metadata": {},
   "source": [
    "## Fix names\n",
    "Folk were not overly consistent with their names..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5494e2-9427-4d0f-8325-6efff8a77396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 20997)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class NameFixer:\n",
    "    lab_heads = {'London Lab': 'Nir London', \n",
    "                 'Chodera Lab': 'John Chodera',\n",
    "                'Lee Lab': 'Alpha Lee',\n",
    "                'Trippier': '?? Trippier', \n",
    "                'Volkamer': '?? Volkamer'}\n",
    "    known = {'Warren': 'Warren Thompson',\n",
    "             'Jag': 'Jag Heer',\n",
    "             'Jan': 'Jan Hullaert'}\n",
    "    weirds = ['Med-Chem team', 'INSCoV',]\n",
    "    redirect = {'Med Chemists Group': 'Med-Chem team',\n",
    "               'Tatiana': 'Tetiana Matviyuk'}\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.unmatched = set()\n",
    "        self.single_names = set()\n",
    "        \n",
    "    def __call__(self, name: str) -> str:\n",
    "        \"\"\"\n",
    "        Find Matt Robinson. Remove titles. Remove initials.\n",
    "        Skip single name folk\n",
    "        \"\"\"\n",
    "        # weird id set\n",
    "        for weird in self.weirds:\n",
    "            if weird in name:\n",
    "                return weird\n",
    "            \n",
    "        s = name.title()\n",
    "        if s in self.redirect:\n",
    "            return self.redirect[s]\n",
    "        for r in self.redirect:\n",
    "            if r in s:\n",
    "                return self.redirect[r]\n",
    "        \n",
    "        if s in ('-', '', ' ', 'Anon', 'Unk'):\n",
    "            return 'anonymous'\n",
    "        \n",
    "        # clean\n",
    "        s = s.replace('Matt ', 'Matthew ')\n",
    "        s = re.sub(r'^Dr.?', '', s)\n",
    "        s = re.sub(r'^Prof.?', '', s)\n",
    "        s = re.sub(r'^(\\w)\\.? ', r'\\1', s)\n",
    "        s = re.sub(r'(\\w)-(\\w)', r'\\1\\2', s)\n",
    "        s = re.sub(r' (\\w)\\.? ', r' ', s)\n",
    "        s = re.sub(r' (\\w) ', r' ', s)\n",
    "        s = re.sub(r'\\s+', r' ', s)\n",
    "        s = re.sub(r' And .*', r'', s)  # title makes and -> And\n",
    "        s = re.sub(r'Inscov.*', 'Inscov', s).strip()\n",
    "        \n",
    "        r = re.match(r'^([ \\w]+)', s)\n",
    "        \n",
    "        if not r:\n",
    "            self.unmatched.add(name)\n",
    "            return ''\n",
    "        \n",
    "        s = r.group(1).strip()\n",
    "        if 'Lab' in s and s in self.lab_heads:\n",
    "            return self.lab_heads[s]\n",
    "        if s in self.redirect:\n",
    "            return self.redirect[s]\n",
    "        if s.count(' ') != 0:\n",
    "            return s\n",
    "        if s in self.known:\n",
    "            return self.known[s]\n",
    "        self.single_names.add(s)\n",
    "        r = re.match(r'^([ \\w]+)[,.&] ([ \\w]+)', name)\n",
    "        if not r:\n",
    "            self.unmatched.add(name)\n",
    "            return 'anonymous'\n",
    "        \n",
    "        return r.group(1).strip()+' '+r.group(2).strip()\n",
    "    \n",
    "    def revisit(self, name, series):\n",
    "        return series.loc[series.str.contains(name)].drop_duplicates()\n",
    "\n",
    "# debug:\n",
    "# dejunk = NameFixer()\n",
    "# for name in ('Ed J Griffen, MedChemica Ltd', 'Jan, Ghent University', 'Ed, Griffen', 'K. Takahashi'):\n",
    "#     print( name, '>', dejunk(name) )\n",
    "\n",
    "dejunk = NameFixer()\n",
    "moonshot['clean_creator'] = moonshot.creator.fillna('').astype(str).apply(dejunk)\n",
    "sum(moonshot['clean_creator'] == ''), len(moonshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33fd57e-f33c-48e5-a35e-a72f28ed486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "moonshot['N_creator_submission'] = moonshot['clean_creator'].map(moonshot['clean_creator'].value_counts())\n",
    "moonshot['N_submission_group'] = moonshot['CID_group'].map(moonshot['CID_group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b1da6-025d-42ce-9e7c-42b2a9ec1742",
   "metadata": {},
   "source": [
    "## remove duplicate CIDs\n",
    "\n",
    "This is a resubmission by wheel reinvention of error in submitter form filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd2621d-c55d-43c1-b493-4ebee4dd43ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "moonshot['resubmitted'] = moonshot.duplicated(subset='CID (canonical)', keep=False)\n",
    "\n",
    "\n",
    "words = defaultdict(str)\n",
    "fragments = defaultdict(set)\n",
    "shipment = defaultdict(list)\n",
    "ordered = defaultdict(list)\n",
    "assayed = defaultdict(bool)\n",
    "made = defaultdict(bool)\n",
    "for i, row in moonshot.loc[moonshot['resubmitted']].iterrows():\n",
    "    cid = row['CID (canonical)']\n",
    "    words[cid] += '. ' + row.description\n",
    "    if row.fragments.strip() != 'x0072':\n",
    "        fragments[cid].update(row.fragments.split(','))\n",
    "    assayed[cid] = assayed[cid] or row.ASSAYED\n",
    "    made[cid] = assayed[cid] or row.MADE\n",
    "    \n",
    "# #\n",
    "moonshot['old_index'] = moonshot.index\n",
    "moonshot = moonshot.drop_duplicates('CID (canonical)').set_index('CID (canonical)', drop=False)\n",
    "for cid in words:\n",
    "    moonshot.at[cid, 'description'] = ','.join(words[cid])\n",
    "    moonshot.at[cid, 'fragments'] = ','.join(fragments[cid])\n",
    "    moonshot.at[cid, 'MADE'] = made[cid]\n",
    "    moonshot.at[cid, 'ASSAYED'] = assayed[cid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07066e9-8e80-478b-850c-e74dee9c2a89",
   "metadata": {},
   "source": [
    "## Include current Fragalysis status\n",
    "\n",
    "This is because the followup details were not updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67af6d97-2372-457a-8060-7085b7a53715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://fragalysis.diamond.ac.uk/api/targets/?title=Mpro')\n",
    "meta_url = response.json()['results'][0]['metadata']\n",
    "response = meta_url = response.json()['results'][0]['metadata']\n",
    "response = requests.get(meta_url)\n",
    "metadata = pd.read_csv(io.StringIO(response.text), index_col=0)\n",
    "in_fragalysis = metadata.alternate_name.to_list()\n",
    "\n",
    "moonshot['in_fragalysis'] = moonshot['CID (canonical)'].isin(in_fragalysis)\n",
    "metadata['xcode'] = metadata['RealCrystalName'].str.split('-', expand=True)[1]\n",
    "for k in ('site_name', 'pdb_entry', 'new_smiles', 'xcode'):\n",
    "    moonshot[k] = moonshot['CID (canonical)'].map(metadata.set_index('alternate_name')[k].to_dict()).fillna('')\n",
    "\n",
    "# px.scatter(moonshot, 'shipment_date', 'submission_date', color='in_fragalysis', opacity=0.2, \n",
    "#            title='Relationship between submission and shipment dates')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c940c-9353-454a-bc6b-b845d6119e8d",
   "metadata": {},
   "source": [
    "## Include submission date\n",
    "Additionally add latest pIC50\n",
    "The file used for the cross referencing is not shared herein due to permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "136b6d52-9351-419b-9239-708b3944434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "dated = pd.read_csv('moonshot_dated_data.csv', index_col=0)\n",
    "# https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\n",
    "for k in ('SUBMITTED_DATE','ORDERED_DATE'):\n",
    "    dated[k.lower()] = pd.to_datetime(dated[k], format='%Y%m%d')\n",
    "import re\n",
    "\n",
    "def fix_ic50(value):\n",
    "    if str(value) == 'nan':\n",
    "        return 100\n",
    "    if isinstance(value, float):\n",
    "        return value\n",
    "    rex = re.search('([\\d.]+)', str(value))\n",
    "    if rex:\n",
    "        return float(rex.group(1))\n",
    "    return 100\n",
    "\n",
    "dated['IC50'] = dated['ProteaseAssay_Fluorescence_Dose-Response_Weizmann: Avg IC50 (uM)'].apply(fix_ic50)\n",
    "moonshot['IC50'] = moonshot['CID (canonical)'].map(dated.IC50)\n",
    "#moonshot['pIC50'] = moonshot['IC50'].apply(np.log10)\n",
    "# IC50 unit is ÂµM hence the +6\n",
    "moonshot['pIC50'] = moonshot.IC50.apply(lambda i: -np.log10(i) + 6)\n",
    "\n",
    "moonshot['submission_date'] = moonshot['CID (canonical)'].map(dated.submitted_date)\n",
    "#moonshot['shipment_date'] = pd.to_datetime(moonshot.SHIPMENT_DATE, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98b67d-204f-44c2-ab64-bf08f5fd4b8e",
   "metadata": {},
   "source": [
    "### Fill empties\n",
    "Now things get hairy: missing values in submission dates.\n",
    "This is because the data comes from the IC50 table (1244 vs. 20,997).\n",
    "Two options:\n",
    "\n",
    "* value from previous using `.fillna(method='ffill')`\n",
    "* monotonic regression\n",
    "\n",
    "The former may cause issues.\n",
    "Monotonic regression is > 1 month over for 6.7% as some clear outliers exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a807f0-1c96-4739-a268-89c089ba0f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction under 0.0\n",
      "Fraction over 0.0\n"
     ]
    }
   ],
   "source": [
    "# this is poor choice:\n",
    "#moonshot['likely_submission_date'] = moonshot['submission_date'].fillna(method='bfill').fillna(method='ffill')\n",
    "#moonshot['likely_submission_month'] = moonshot['likely_submission_date'].apply(lambda d: d.month + 12 * (d.year -2020))\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from datetime import date, timedelta\n",
    "\n",
    "iso = IsotonicRegression(out_of_bounds='clip')\n",
    "iso.fit(*list(zip(*[(i,v.toordinal()) for i,v in enumerate(moonshot.submission_date) if str(v) != 'NaT'])))\n",
    "moonshot['inferred_submission_date'] = pd.Series(iso.predict(np.arange(len(moonshot.submission_date)))).astype(int).apply(datetime.fromordinal).values\n",
    "moonshot['inferred_submission_month'] = moonshot['inferred_submission_date'].apply(lambda d: d.month + 12 * (d.year -2020))\n",
    "\n",
    "print('Fraction under', sum(moonshot.submission_date + timedelta(days=30) < (moonshot.inferred_submission_date))/sum(~moonshot.submission_date.isna()))\n",
    "print('Fraction over', sum(moonshot.submission_date >= moonshot.inferred_submission_date + timedelta(days=1))/sum(~moonshot.submission_date.isna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e553227-7fea-45c2-8d88-70a515cf007b",
   "metadata": {},
   "source": [
    "##  Simple word counts etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca6f6bd-2acf-41c2-b249-2ba272d815a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "moonshot['N_chars'] = moonshot.description.apply(len)\n",
    "moonshot['N_words'] = moonshot.description.apply(lambda x: len(re.findall(r'[\\w-]+',x)))\n",
    "\n",
    "# Some submitters copypasted abstracts...\n",
    "moonshot['N_words_cutoff'] = moonshot.N_words.apply(lambda v: v if v < 500 else float('nan'))\n",
    "\n",
    "\n",
    "# use `in_fragalysis`\n",
    "# moonshot['CRYSTALLISED'] = moonshot['Structure ID'] != ''\n",
    "# moonshot['crystallised'] = moonshot['Structure ID'] != ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2005c-2e46-4d34-9917-e58ae4a364ed",
   "metadata": {},
   "source": [
    "## Term classification\n",
    "This is the result of a manual inspection of way too many entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4784847e-4fad-4169-aab7-e40b63a30fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum, operator\n",
    "\n",
    "class Method(enum.Enum):\n",
    "    INITIAL = enum.auto()  # these were possibly poised libary â€” not checked\n",
    "    OLD = enum.auto()  # original SARS inhibitor\n",
    "    MANUAL = enum.auto()\n",
    "    MANUAL_POSSIBLY = enum.auto()\n",
    "    DOCKING = enum.auto()\n",
    "    FEP = enum.auto()\n",
    "    UNKNOWN = enum.auto()\n",
    "\n",
    "\n",
    "def classify(row):\n",
    "    def has_any_term(*terms):\n",
    "        return any([term in row.description.lower() for term in terms])\n",
    "        \n",
    "    if has_any_term('missing fragalysis structures',\n",
    "                    'first batch of fragments so we have a moonshot cid for them',\n",
    "                    'fragment that was missing an id not a design but a frament',\n",
    "                   'second batch of submissions of fragments in order to generate moonshot cid',\n",
    "                   'final set of fragments so we can generate moonshot cid'):\n",
    "        return Method.INITIAL\n",
    "    if has_any_term('sars inhibitor'):\n",
    "        return Method.OLD\n",
    "    if has_any_term('fep'):\n",
    "        return Method.FEP\n",
    "    if has_any_term('dock', 'seesar', 'vina', 'autodock', 'screen', 'drug-hunter', 'search'):\n",
    "        return Method.DOCKING\n",
    "    if has_any_term('by-eye', 'merg', 'link', 'coupl'):\n",
    "        return Method.MANUAL\n",
    "    if has_any_term('swap', 'racem', 'side product', 'intermediate', 'break',\n",
    "                    'bioisoster', 'isomer', 'around', 'replace', 'isomer', 'enantiomer',\n",
    "                    'introduction', 'substitution', 'shifted', 'combo',\n",
    "                    'expansion', 'made by', 'design', 'idea', 'based', 'pairs',\n",
    "                    'modification', 'derivative', 'common sense', 'suggested',\n",
    "                    'similar to', 'analogues', 'easy to make', 'exploration', 'inspir', 'possible'):\n",
    "        return Method.MANUAL_POSSIBLY\n",
    "    if len(row.description) > 200:\n",
    "        return Method.MANUAL_POSSIBLY \n",
    "    if row.fragments != 'x0072':\n",
    "        return Method.MANUAL_POSSIBLY\n",
    "    return Method.UNKNOWN\n",
    "    \n",
    "moonshot['classified_method'] = moonshot.apply(classify, axis=1).apply(operator.attrgetter('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fbf3dcd-31df-47f2-9317-65144a1e6dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/matteo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09943306-b505-4a07-a633-4627e45deb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "penta_words = (moonshot.description + '. ') * 5\n",
    "\n",
    "from readability import Readability\n",
    "from readability.exceptions import ReadabilityException\n",
    "\n",
    "def flesch_score(text: str) -> float:\n",
    "    try:\n",
    "        return Readability(text).flesch_kincaid().score\n",
    "    except ReadabilityException as error:\n",
    "        return np.nan\n",
    "    \n",
    "def dale_score(text: str) -> float:\n",
    "    try:\n",
    "        return Readability(text).dale_chall().score\n",
    "    except ReadabilityException as error:\n",
    "        return np.nan\n",
    "    \n",
    "moonshot['flesch'] = penta_words.apply(flesch_score)\n",
    "moonshot['dale_chall'] = penta_words.apply(dale_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eddc971-68b0-464a-9574-2a97ca4f83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "moonshot['initial_screen'] = moonshot.site_name.str.contains('XChem Screen')\n",
    "\n",
    "for i in moonshot.index[moonshot.initial_screen]:\n",
    "    moonshot.at[i, 'classified_method'] = 'STARTING_LIBRARY'\n",
    "    moonshot.at[i, 'clean_creator'] = 'DSi-Poised Library'\n",
    "    for k in ('submission_date','inferred_submission_date','shipment_date'):\n",
    "        moonshot.at[i, k] = pd.Timestamp(year=2020, month=2, day=1)\n",
    "    \n",
    "for  i in moonshot.index[moonshot.description.str.contains('SARS inhibitors')]:\n",
    "    moonshot.at[i, 'classified_method'] = 'PRIOR_SARS_INHIBITOR'\n",
    "\n",
    "moonshot['okay'] = ~moonshot.clean_creator.isin(['Mark Davies', 'Maksym Voznyy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1abbf74a-2253-447f-9664-41a297f41a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moonshot.copy().to_pickle('moonshot_submissions.p')\n",
    "moonshot.to_csv('moonshot_submissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f03ce79-1ad5-48c7-82fa-032b7f8909a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "moonshot[['CID (canonical)','CID_group', 'old_index', 'clean_creator', 'SMILES', 'new_smiles',\n",
    "                           'fragments', 'xcode', 'Structure ID', 'xcode','site_name', 'pdb_entry',\n",
    "                            'ORDERED', 'MADE', 'ASSAYED', 'in_fragalysis',\n",
    "                            'IC50', 'pIC50',\n",
    "                           'submission_date', 'inferred_submission_date', 'order_date', 'shipment_date', \n",
    "                           'description',\n",
    "                           'N_creator_submission', 'N_submission_group', 'resubmitted',\n",
    "                           'Enamine - REAL Space', 'Enamine - Extended REAL Space',\n",
    "                           'Enamine - SCR', 'Enamine - BB', 'Mcule', 'Mcule Ultimate',\n",
    "                           'N_chars', 'N_words', 'N_words_cutoff', 'classified_method', 'flesch',\n",
    "                           'dale_chall', 'okay']].to_csv('moonshot_submissions.min.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588fb6a4-4bec-44f6-86f5-ac58de298949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
